{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56c01712",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Week 01 — Introduction to Financial Modelling & ML Basics\"\n",
    "week: 1\n",
    "author: \"Praveen Kumar\"\n",
    "date: 2025-10-07\n",
    "duration: \"2-3 hours\"\n",
    "prerequisites: [\"Basic Python\", \"High school algebra\"]\n",
    "tags: [\"intro\",\"linear-regression\",\"financial-modeling\"]\n",
    "version: v1.0\n",
    "---\n",
    "\n",
    "# Week 01 — Introduction to Financial Modelling & ML Basics\n",
    "\n",
    "## Student Notebook: Linear Regression for Stock Return Prediction\n",
    "\n",
    "This notebook introduces the fundamentals of financial modelling using machine learning. We'll implement a basic linear regression model to predict stock returns using historical lag features.\n",
    "\n",
    "### Learning Objectives:\n",
    "- Understand financial time series data structure\n",
    "- Implement feature engineering with lag variables\n",
    "- Train and evaluate a linear regression model\n",
    "- Visualize model performance and interpret results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddc979ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "SEED: 42\n",
      "SAMPLE_MODE: True\n",
      "DATA_PATH: data/synthetic/\n",
      "DATASET: stock_prices.csv\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "SEED = 42\n",
    "SAMPLE_MODE = True  # Set to True for quick runs, False for full analysis\n",
    "DATA_PATH = \"data/synthetic/\"\n",
    "DATASET = \"stock_prices.csv\"\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"SEED: {SEED}\")\n",
    "print(f\"SAMPLE_MODE: {SAMPLE_MODE}\")\n",
    "print(f\"DATA_PATH: {DATA_PATH}\")\n",
    "print(f\"DATASET: {DATASET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d28a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run only if needed)\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    import yfinance\n",
    "    print(\"yfinance already installed\")\n",
    "except ImportError:\n",
    "    print(\"Installing yfinance...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"yfinance\", \"-q\"])\n",
    "    print(\"yfinance installed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e25c4dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete!\n",
      "NumPy version: 2.3.3\n",
      "Pandas version: 2.3.3\n",
      "YFinance available: True\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Financial data\n",
    "try:\n",
    "    import yfinance as yf\n",
    "    YF_AVAILABLE = True\n",
    "except ImportError:\n",
    "    YF_AVAILABLE = False\n",
    "    print(\"Warning: yfinance not available. Will use synthetic data only.\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(SEED)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure plotting\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"Setup Complete!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"YFinance available: {YF_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173f7a2f",
   "metadata": {},
   "source": [
    "## Section 1: Data Loading and Preprocessing\n",
    "\n",
    "We'll load stock price data with a fallback strategy:\n",
    "1. First, try to load from synthetic CSV file (for offline/quick runs)\n",
    "2. If not available, download AAPL data using yfinance\n",
    "3. Handle any data loading issues gracefully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "220de221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading AAPL data from Yahoo Finance...\n",
      "Successfully downloaded data: (250, 5)\n",
      "\n",
      "Data source: yfinance\n",
      "Date range: 2023-01-03 00:00:00 to 2023-12-29 00:00:00\n",
      "Available columns: [('Close', 'AAPL'), ('High', 'AAPL'), ('Low', 'AAPL'), ('Open', 'AAPL'), ('Volume', 'AAPL')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-03</th>\n",
       "      <td>123.330658</td>\n",
       "      <td>129.079575</td>\n",
       "      <td>122.443173</td>\n",
       "      <td>128.468202</td>\n",
       "      <td>112117500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04</th>\n",
       "      <td>124.602707</td>\n",
       "      <td>126.870724</td>\n",
       "      <td>123.340509</td>\n",
       "      <td>125.125335</td>\n",
       "      <td>89113600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-05</th>\n",
       "      <td>123.281342</td>\n",
       "      <td>125.993097</td>\n",
       "      <td>123.024963</td>\n",
       "      <td>125.361998</td>\n",
       "      <td>80962700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-06</th>\n",
       "      <td>127.817383</td>\n",
       "      <td>128.478063</td>\n",
       "      <td>123.153167</td>\n",
       "      <td>124.257594</td>\n",
       "      <td>87754700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-09</th>\n",
       "      <td>128.339981</td>\n",
       "      <td>131.554653</td>\n",
       "      <td>128.083602</td>\n",
       "      <td>128.655538</td>\n",
       "      <td>70790800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price            Close        High         Low        Open     Volume\n",
       "Ticker            AAPL        AAPL        AAPL        AAPL       AAPL\n",
       "Date                                                                 \n",
       "2023-01-03  123.330658  129.079575  122.443173  128.468202  112117500\n",
       "2023-01-04  124.602707  126.870724  123.340509  125.125335   89113600\n",
       "2023-01-05  123.281342  125.993097  123.024963  125.361998   80962700\n",
       "2023-01-06  127.817383  128.478063  123.153167  124.257594   87754700\n",
       "2023-01-09  128.339981  131.554653  128.083602  128.655538   70790800"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Loading with Fallback Logic\n",
    "def load_stock_data():\n",
    "    \"\"\"Load stock data with fallback logic.\"\"\"\n",
    "    data = None\n",
    "    \n",
    "    # Strategy 1: Try to load synthetic data first\n",
    "    synthetic_path = os.path.join(DATA_PATH, DATASET)\n",
    "    if os.path.exists(synthetic_path):\n",
    "        try:\n",
    "            print(f\"Loading synthetic data from {synthetic_path}\")\n",
    "            data = pd.read_csv(synthetic_path, index_col=0, parse_dates=True)\n",
    "            print(f\"Successfully loaded synthetic data: {data.shape}\")\n",
    "            return data, \"synthetic\"\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load synthetic data: {e}\")\n",
    "    \n",
    "    # Strategy 2: Download from yfinance (if available)\n",
    "    if YF_AVAILABLE:\n",
    "        try:\n",
    "            print(\"Downloading AAPL data from Yahoo Finance...\")\n",
    "            # Use different date ranges based on SAMPLE_MODE\n",
    "            if SAMPLE_MODE:\n",
    "                # Small sample for quick runs\n",
    "                data = yf.download('AAPL', start='2023-01-01', end='2024-01-01', progress=False)\n",
    "            else:\n",
    "                # Larger dataset for full analysis\n",
    "                data = yf.download('AAPL', start='2020-01-01', end='2024-01-01', progress=False)\n",
    "            \n",
    "            print(f\"Successfully downloaded data: {data.shape}\")\n",
    "            return data, \"yfinance\"\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download data: {e}\")\n",
    "    \n",
    "    # Fallback: Create synthetic data\n",
    "    print(\"Creating synthetic stock data...\")\n",
    "    dates = pd.date_range(start='2023-01-01', end='2024-01-01', freq='D')\n",
    "    np.random.seed(SEED)\n",
    "    \n",
    "    # Generate synthetic stock price with random walk\n",
    "    returns = np.random.normal(0.001, 0.02, len(dates))  # Mean return 0.1%, volatility 2%\n",
    "    prices = 100 * np.exp(np.cumsum(returns))\n",
    "    \n",
    "    data = pd.DataFrame({\n",
    "        'Open': prices * np.random.uniform(0.98, 1.02, len(dates)),\n",
    "        'High': prices * np.random.uniform(1.00, 1.05, len(dates)),\n",
    "        'Low': prices * np.random.uniform(0.95, 1.00, len(dates)),\n",
    "        'Close': prices,\n",
    "        'Volume': np.random.randint(1000000, 10000000, len(dates)),\n",
    "        'Adj Close': prices\n",
    "    }, index=dates)\n",
    "    \n",
    "    print(f\"Created synthetic data: {data.shape}\")\n",
    "    return data, \"synthetic_generated\"\n",
    "\n",
    "# Load the data\n",
    "stock_data, data_source = load_stock_data()\n",
    "print(f\"\\nData source: {data_source}\")\n",
    "print(f\"Date range: {stock_data.index.min()} to {stock_data.index.max()}\")\n",
    "print(f\"Available columns: {list(stock_data.columns)}\")\n",
    "stock_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa64fa93",
   "metadata": {},
   "source": [
    "## Section 2: Feature Engineering for Financial Time Series\n",
    "\n",
    "Now we'll create features for our machine learning model:\n",
    "1. Calculate daily returns\n",
    "2. Create lag features (previous 5 days' returns)\n",
    "3. Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490eb810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "def create_features(data, price_column='Adj Close'):\n",
    "    \"\"\"Create features for ML model.\"\"\"\n",
    "    df = data.copy()\n",
    "    \n",
    "    # Calculate daily returns\n",
    "    df['Return'] = df[price_column].pct_change()\n",
    "    \n",
    "    # Create lag features (previous 5 days' returns)\n",
    "    for i in range(1, 6):\n",
    "        df[f'Lag_{i}'] = df['Return'].shift(i)\n",
    "    \n",
    "    # Drop missing values\n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create features\n",
    "feature_data = create_features(stock_data)\n",
    "\n",
    "print(f\"Feature engineering complete!\")\n",
    "print(f\"Original data shape: {stock_data.shape}\")\n",
    "print(f\"Feature data shape: {feature_data.shape}\")\n",
    "print(f\"\\nFeature columns: {[col for col in feature_data.columns if 'Lag_' in col]}\")\n",
    "\n",
    "# Display sample of engineered features\n",
    "feature_data[['Return', 'Lag_1', 'Lag_2', 'Lag_3', 'Lag_4', 'Lag_5']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5892cb22",
   "metadata": {},
   "source": [
    "## Section 3: Model Preparation and Training\n",
    "\n",
    "We'll prepare our data for machine learning:\n",
    "1. Split features (X) and target (y)\n",
    "2. Perform chronological train/test split (80/20)\n",
    "3. Train a Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f0e3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "feature_columns = ['Lag_1', 'Lag_2', 'Lag_3', 'Lag_4', 'Lag_5']\n",
    "X = feature_data[feature_columns]\n",
    "y = feature_data['Return']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "\n",
    "# Chronological split (important for time series!)\n",
    "split_idx = int(0.8 * len(feature_data))\n",
    "split_date = feature_data.index[split_idx]\n",
    "\n",
    "X_train = X.iloc[:split_idx]\n",
    "X_test = X.iloc[split_idx:]\n",
    "y_train = y.iloc[:split_idx]\n",
    "y_test = y.iloc[split_idx:]\n",
    "\n",
    "print(f\"\\nTrain set: {X_train.shape[0]} samples (up to {split_date.date()})\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples (from {split_date.date()})\")\n",
    "print(f\"Train period: {X_train.index.min().date()} to {X_train.index.max().date()}\")\n",
    "print(f\"Test period: {X_test.index.min().date()} to {X_test.index.max().date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caa3c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Linear Regression Model\n",
    "# Using a pipeline with standardization (good practice for linear models)\n",
    "model_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "print(\"Training Linear Regression model...\")\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = model_pipeline.predict(X_train)\n",
    "y_test_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "print(\"Model training complete!\")\n",
    "print(f\"Model coefficients shape: {model_pipeline.named_steps['regressor'].coef_.shape}\")\n",
    "\n",
    "# Display model coefficients\n",
    "coefficients = model_pipeline.named_steps['regressor'].coef_\n",
    "intercept = model_pipeline.named_steps['regressor'].intercept_\n",
    "\n",
    "print(f\"\\nModel Equation:\")\n",
    "print(f\"Return(t) = {intercept:.6f}\", end=\"\")\n",
    "for i, coef in enumerate(coefficients):\n",
    "    sign = \"+\" if coef >= 0 else \"\"\n",
    "    print(f\" {sign}{coef:.6f}*Lag_{i+1}\", end=\"\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Create coefficient DataFrame for better visualization\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "print(\"Feature Coefficients:\")\n",
    "print(coef_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61db0a80",
   "metadata": {},
   "source": [
    "## Section 4: Model Evaluation\n",
    "\n",
    "Let's evaluate our model's performance using standard regression metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7e4707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "def evaluate_model(y_true, y_pred, dataset_name=\"\"):\n",
    "    \"\"\"Calculate and display evaluation metrics.\"\"\"\n",
    "    mse = metrics.mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = metrics.r2_score(y_true, y_pred)\n",
    "    mae = metrics.mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n{dataset_name} Set Performance:\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.8f}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.6f}\")\n",
    "    print(f\"R-squared (R²): {r2:.6f}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.6f}\")\n",
    "    \n",
    "    return {'MSE': mse, 'RMSE': rmse, 'R2': r2, 'MAE': mae}\n",
    "\n",
    "# Evaluate on both sets\n",
    "train_metrics = evaluate_model(y_train, y_train_pred, \"Training\")\n",
    "test_metrics = evaluate_model(y_test, y_test_pred, \"Test\")\n",
    "\n",
    "# Summary comparison\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"SUMMARY COMPARISON:\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"{'Metric':<15} {'Train':<12} {'Test':<12} {'Difference':<12}\")\n",
    "print(f\"{'-'*50}\")\n",
    "for metric in ['MSE', 'R2']:\n",
    "    train_val = train_metrics[metric]\n",
    "    test_val = test_metrics[metric]\n",
    "    diff = test_val - train_val\n",
    "    print(f\"{metric:<15} {train_val:<12.6f} {test_val:<12.6f} {diff:<12.6f}\")\n",
    "\n",
    "# Interpretation\n",
    "print(f\"\\nInterpretation:\")\n",
    "if test_metrics['R2'] > 0:\n",
    "    print(f\"✓ Model explains {test_metrics['R2']*100:.2f}% of variance in test returns\")\n",
    "else:\n",
    "    print(f\"✗ Model performs worse than simply predicting the mean return\")\n",
    "\n",
    "if abs(test_metrics['R2'] - train_metrics['R2']) < 0.1:\n",
    "    print(f\"✓ Model shows good generalization (low overfitting)\")\n",
    "else:\n",
    "    print(f\"⚠ Model may be overfitting (large train-test performance gap)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf931ff",
   "metadata": {},
   "source": [
    "## Section 5: Visualization and Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f163fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Actual vs Predicted Returns (Test Set)\n",
    "axes[0, 0].scatter(y_test, y_test_pred, alpha=0.6, color='blue')\n",
    "axes[0, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[0, 0].set_xlabel('Actual Returns')\n",
    "axes[0, 0].set_ylabel('Predicted Returns')\n",
    "axes[0, 0].set_title(f'Actual vs Predicted Returns (Test Set)\\nR² = {test_metrics[\"R2\"]:.4f}')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Residual Plot\n",
    "residuals = y_test - y_test_pred\n",
    "axes[0, 1].scatter(y_test_pred, residuals, alpha=0.6, color='green')\n",
    "axes[0, 1].axhline(y=0, color='r', linestyle='--')\n",
    "axes[0, 1].set_xlabel('Predicted Returns')\n",
    "axes[0, 1].set_ylabel('Residuals (Actual - Predicted)')\n",
    "axes[0, 1].set_title('Residual Plot')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Model Coefficients\n",
    "coef_names = [f'Lag_{i+1}' for i in range(len(coefficients))]\n",
    "colors = ['red' if c < 0 else 'blue' for c in coefficients]\n",
    "bars = axes[1, 0].bar(coef_names, coefficients, color=colors, alpha=0.7)\n",
    "axes[1, 0].axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "axes[1, 0].set_xlabel('Lag Features')\n",
    "axes[1, 0].set_ylabel('Coefficient Value')\n",
    "axes[1, 0].set_title('Model Coefficients by Lag Period')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, coef in zip(bars, coefficients):\n",
    "    height = bar.get_height()\n",
    "    axes[1, 0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{coef:.4f}', ha='center', va='bottom' if height > 0 else 'top')\n",
    "\n",
    "# 4. Time Series of Actual vs Predicted (last 50 points for clarity)\n",
    "n_display = min(50, len(y_test))\n",
    "test_dates = y_test.index[-n_display:]\n",
    "axes[1, 1].plot(test_dates, y_test[-n_display:], 'b-', label='Actual', linewidth=2)\n",
    "axes[1, 1].plot(test_dates, y_test_pred[-n_display:], 'r--', label='Predicted', linewidth=2)\n",
    "axes[1, 1].set_xlabel('Date')\n",
    "axes[1, 1].set_ylabel('Return')\n",
    "axes[1, 1].set_title(f'Recent Predictions vs Actual (Last {n_display} days)')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Additional insights\n",
    "print(\"Model Insights:\")\n",
    "print(f\"1. Most influential lag: Lag_{np.argmax(np.abs(coefficients)) + 1} (coefficient: {coefficients[np.argmax(np.abs(coefficients))]:.6f})\")\n",
    "print(f\"2. Model captures {'momentum' if coefficients[0] > 0 else 'mean reversion'} in daily returns\")\n",
    "print(f\"3. Average absolute coefficient: {np.mean(np.abs(coefficients)):.6f}\")\n",
    "print(f\"4. Residual standard deviation: {np.std(residuals):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e8f90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to CSV for submission\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Date': y_test.index,\n",
    "    'Actual_Return': y_test.values,\n",
    "    'Predicted_Return': y_test_pred,\n",
    "    'Residual': y_test.values - y_test_pred\n",
    "})\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = '/kaggle/working' if '/kaggle' in os.getcwd() else 'output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "output_path = os.path.join(output_dir, 'predictions_week01.csv')\n",
    "predictions_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Predictions saved to: {output_path}\")\n",
    "print(f\"File contains {len(predictions_df)} predictions\")\n",
    "print(\"\\nFirst few predictions:\")\n",
    "print(predictions_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4991da33",
   "metadata": {},
   "source": [
    "## Section 6: Student Exercises\n",
    "\n",
    "Complete the following exercises to deepen your understanding of financial ML concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a97d35a",
   "metadata": {},
   "source": [
    "### Exercise 1: Implement Ridge Regression\n",
    "\n",
    "Ridge regression adds L2 regularization to prevent overfitting. Compare its performance with our baseline Linear Regression model.\n",
    "\n",
    "**Hint:** Use `sklearn.linear_model.Ridge` instead of `LinearRegression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec72ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Exercise 1 - Implement Ridge Regression\n",
    "# Your task:\n",
    "# 1. Create a Ridge regression model using sklearn.linear_model.Ridge\n",
    "# 2. Train it on the same training data (X_train, y_train)\n",
    "# 3. Make predictions on the test set\n",
    "# 4. Calculate MSE and R² for comparison\n",
    "# 5. Compare coefficients with the Linear Regression model\n",
    "\n",
    "# Ridge regression pipeline\n",
    "ridge_pipeline = None  # TODO: Create pipeline with StandardScaler and Ridge\n",
    "\n",
    "# Train and evaluate\n",
    "# TODO: Fit the model, make predictions, and calculate metrics\n",
    "\n",
    "# Compare results\n",
    "# TODO: Print comparison of Linear vs Ridge performance\n",
    "\n",
    "print(\"Exercise 1: Complete the Ridge regression implementation above!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35af7855",
   "metadata": {},
   "source": [
    "### Exercise 2: Add Rolling Volatility Feature\n",
    "\n",
    "Financial volatility is an important feature. Create a 5-day rolling volatility and assess whether it improves model performance.\n",
    "\n",
    "**Hint:** Use `df['Return'].rolling(5).std()` to calculate rolling volatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfb68c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Exercise 2 - Add Rolling Volatility Feature\n",
    "# Your task:\n",
    "# 1. Calculate 5-day rolling volatility: volatility = returns.rolling(5).std()\n",
    "# 2. Add this as a new feature to your existing lag features\n",
    "# 3. Re-train the Linear Regression model with lag features + volatility\n",
    "# 4. Compare performance with the original model (lags only)\n",
    "# 5. Visualize the volatility feature over time\n",
    "\n",
    "# Create enhanced feature set\n",
    "def create_enhanced_features(data, price_column='Adj Close'):\n",
    "    \"\"\"Create features including volatility.\"\"\"\n",
    "    df = data.copy()\n",
    "    df['Return'] = df[price_column].pct_change()\n",
    "    \n",
    "    # Original lag features\n",
    "    for i in range(1, 6):\n",
    "        df[f'Lag_{i}'] = df['Return'].shift(i)\n",
    "    \n",
    "    # TODO: Add rolling volatility feature\n",
    "    # df['Volatility_5d'] = ???\n",
    "    \n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "# TODO: Create enhanced features, train model, and compare results\n",
    "\n",
    "print(\"Exercise 2: Complete the rolling volatility implementation above!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e76547",
   "metadata": {},
   "source": [
    "### Exercise 3: Different Train/Test Split Analysis\n",
    "\n",
    "Time series models can be sensitive to the train/test split. Experiment with different split ratios and observe the impact.\n",
    "\n",
    "**Hint:** Try 70/30 and 90/10 splits and compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712538fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Exercise 3 - Different Train/Test Split Analysis\n",
    "# Your task:\n",
    "# 1. Test different train/test split ratios: 70/30, 90/10\n",
    "# 2. Train the same Linear Regression model for each split\n",
    "# 3. Compare the R² and MSE across different splits\n",
    "# 4. Discuss why the split ratio might affect performance in time series\n",
    "\n",
    "def train_with_split(X, y, train_ratio=0.8):\n",
    "    \"\"\"Train model with custom split ratio.\"\"\"\n",
    "    split_idx = int(train_ratio * len(X))\n",
    "    # TODO: Implement custom split training and evaluation\n",
    "    pass\n",
    "\n",
    "# Test different splits\n",
    "split_ratios = [0.7, 0.8, 0.9]\n",
    "results = {}\n",
    "\n",
    "# TODO: Loop through split ratios and collect results\n",
    "# for ratio in split_ratios:\n",
    "#     results[ratio] = train_with_split(X, y, ratio)\n",
    "\n",
    "# TODO: Create comparison table/visualization\n",
    "\n",
    "print(\"Exercise 3: Complete the train/test split analysis above!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d48d291",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congratulations! You've completed Week 1 of the Financial Modelling using Machine Learning Bootcamp. \n",
    "\n",
    "### What you learned:\n",
    "- Financial time series data structure and characteristics\n",
    "- Feature engineering with lag variables for stock returns\n",
    "- Linear regression implementation and evaluation\n",
    "- Model interpretation through coefficients and visualizations\n",
    "- Common evaluation metrics (MSE, R²) for regression problems\n",
    "\n",
    "### Key takeaways:\n",
    "1. **Time series requires chronological splits** - Never shuffle time series data randomly\n",
    "2. **Feature engineering is crucial** - Raw prices are less useful than returns and lags\n",
    "3. **Regularization helps** - Ridge regression can improve generalization\n",
    "4. **Financial data is noisy** - Perfect predictions are unrealistic; focus on consistent patterns\n",
    "\n",
    "### Next steps:\n",
    "- Complete the exercises above\n",
    "- Try the weekly assignment\n",
    "- Explore different stocks and time periods\n",
    "- Consider other features like technical indicators\n",
    "\n",
    "Great work! See you in Week 2 where we'll explore more sophisticated ML algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
