{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33f6d704",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Week 01 — Introduction to Financial Modelling & ML Basics\"\n",
    "week: 1\n",
    "author: \"Praveen Kumar\"\n",
    "date: 2025-10-07\n",
    "duration: \"2-3 hours\"\n",
    "prerequisites: [\"Basic Python\", \"High school algebra\"]\n",
    "tags: [\"intro\",\"linear-regression\",\"financial-modeling\"]\n",
    "version: v1.0\n",
    "instructor_only: true\n",
    "---\n",
    "\n",
    "# Week 01 — Introduction to Financial Modelling & ML Basics\n",
    "\n",
    "## INSTRUCTOR NOTEBOOK: Linear Regression for Stock Return Prediction\n",
    "\n",
    "This notebook contains the complete solutions for all exercises and additional teaching materials.\n",
    "\n",
    "**⚠️ INSTRUCTOR ONLY - Remove solution cells before distributing to students**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade0aff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "SEED = 42\n",
    "SAMPLE_MODE = True  # Set to True for quick runs, False for full analysis\n",
    "DATA_PATH = \"data/synthetic/\"\n",
    "DATASET = \"stock_prices.csv\"\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"SEED: {SEED}\")\n",
    "print(f\"SAMPLE_MODE: {SAMPLE_MODE}\")\n",
    "print(f\"DATA_PATH: {DATA_PATH}\")\n",
    "print(f\"DATASET: {DATASET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98bf4ab",
   "metadata": {},
   "source": [
    "## Teaching Notes for Instructors\n",
    "\n",
    "### Expected Results and Common Student Mistakes:\n",
    "\n",
    "1. **Linear Regression Model Performance**:\n",
    "   - Expected R² on test set: 0.01 to 0.05 (stock returns are inherently noisy)\n",
    "   - MSE typically around 0.0003-0.001 for daily returns\n",
    "   - Students often expect higher R² values - explain that financial data is noisy\n",
    "\n",
    "2. **Common Student Mistakes**:\n",
    "   - Using random splits instead of chronological splits (data leakage)\n",
    "   - Expecting high R² values like in other domains\n",
    "   - Not standardizing features for linear models\n",
    "   - Misinterpreting negative R² as model failure\n",
    "   - Forgetting to set random seed for reproducibility\n",
    "\n",
    "3. **Grading Points**:\n",
    "   - Correct chronological split: 20 points\n",
    "   - Proper feature engineering (lags): 25 points  \n",
    "   - Model implementation and training: 25 points\n",
    "   - Evaluation metrics calculation: 15 points\n",
    "   - Visualizations and interpretation: 15 points\n",
    "\n",
    "### Sample Expected Outputs:\n",
    "- Linear Regression Test R²: ~0.02-0.05\n",
    "- Ridge Regression typically shows similar or slightly better R²\n",
    "- Most influential lag is usually Lag_1 (momentum effect)\n",
    "- Volatility feature may improve R² by 0.01-0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0620ba",
   "metadata": {},
   "source": [
    "## Exercise Solutions (INSTRUCTOR ONLY)\n",
    "\n",
    "### Exercise 1 Solution: Ridge Regression Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086b7feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTRUCTOR ONLY - Exercise 1 Solution: Ridge Regression\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Create Ridge regression pipeline\n",
    "ridge_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', Ridge(alpha=1.0, random_state=SEED))\n",
    "])\n",
    "\n",
    "# Train Ridge model\n",
    "ridge_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_ridge = ridge_pipeline.predict(X_train)\n",
    "y_test_pred_ridge = ridge_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate Ridge model\n",
    "ridge_train_metrics = evaluate_model(y_train, y_train_pred_ridge, \"Ridge Training\")\n",
    "ridge_test_metrics = evaluate_model(y_test, y_test_pred_ridge, \"Ridge Test\")\n",
    "\n",
    "# Compare Linear vs Ridge\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"LINEAR REGRESSION vs RIDGE REGRESSION COMPARISON\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"{'Metric':<15} {'Linear (Test)':<15} {'Ridge (Test)':<15} {'Improvement':<15}\")\n",
    "print(f\"{'-'*60}\")\n",
    "\n",
    "for metric in ['MSE', 'R2']:\n",
    "    linear_val = test_metrics[metric]\n",
    "    ridge_val = ridge_test_metrics[metric]\n",
    "    improvement = ridge_val - linear_val if metric == 'R2' else linear_val - ridge_val\n",
    "    print(f\"{metric:<15} {linear_val:<15.6f} {ridge_val:<15.6f} {improvement:<15.6f}\")\n",
    "\n",
    "# Compare coefficients\n",
    "ridge_coefficients = ridge_pipeline.named_steps['regressor'].coef_\n",
    "linear_coefficients = coefficients\n",
    "\n",
    "print(f\"\\nCoefficient Comparison:\")\n",
    "coef_comparison = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Linear_Coef': linear_coefficients,\n",
    "    'Ridge_Coef': ridge_coefficients,\n",
    "    'Difference': np.abs(linear_coefficients - ridge_coefficients)\n",
    "})\n",
    "print(coef_comparison)\n",
    "\n",
    "print(f\"\\nRidge regularization effect:\")\n",
    "print(f\"- Average absolute coefficient reduction: {np.mean(coef_comparison['Difference']):.6f}\")\n",
    "print(f\"- Ridge coefficients are {'more' if np.mean(np.abs(ridge_coefficients)) < np.mean(np.abs(linear_coefficients)) else 'less'} regularized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611740de",
   "metadata": {},
   "source": [
    "### Exercise 2 Solution: Rolling Volatility Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa61536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTRUCTOR ONLY - Exercise 2 Solution: Rolling Volatility Feature\n",
    "\n",
    "def create_enhanced_features(data, price_column='Adj Close'):\n",
    "    \"\"\"Create features including volatility.\"\"\"\n",
    "    df = data.copy()\n",
    "    df['Return'] = df[price_column].pct_change()\n",
    "    \n",
    "    # Original lag features\n",
    "    for i in range(1, 6):\n",
    "        df[f'Lag_{i}'] = df['Return'].shift(i)\n",
    "    \n",
    "    # Add rolling volatility feature (5-day window)\n",
    "    df['Volatility_5d'] = df['Return'].rolling(5).std()\n",
    "    \n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "# Create enhanced features\n",
    "enhanced_data = create_enhanced_features(stock_data)\n",
    "print(f\"Enhanced feature data shape: {enhanced_data.shape}\")\n",
    "\n",
    "# Prepare enhanced feature set\n",
    "enhanced_feature_columns = ['Lag_1', 'Lag_2', 'Lag_3', 'Lag_4', 'Lag_5', 'Volatility_5d']\n",
    "X_enhanced = enhanced_data[enhanced_feature_columns]\n",
    "y_enhanced = enhanced_data['Return']\n",
    "\n",
    "# Split data chronologically\n",
    "split_idx = int(0.8 * len(enhanced_data))\n",
    "X_train_enh = X_enhanced.iloc[:split_idx]\n",
    "X_test_enh = X_enhanced.iloc[split_idx:]\n",
    "y_train_enh = y_enhanced.iloc[:split_idx]\n",
    "y_test_enh = y_enhanced.iloc[split_idx:]\n",
    "\n",
    "# Train enhanced model\n",
    "enhanced_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "enhanced_pipeline.fit(X_train_enh, y_train_enh)\n",
    "y_test_pred_enh = enhanced_pipeline.predict(X_test_enh)\n",
    "\n",
    "# Evaluate enhanced model\n",
    "enhanced_metrics = evaluate_model(y_test_enh, y_test_pred_enh, \"Enhanced (with Volatility)\")\n",
    "\n",
    "# Compare original vs enhanced\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ORIGINAL vs ENHANCED (WITH VOLATILITY) COMPARISON\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"{'Metric':<15} {'Original':<15} {'Enhanced':<15} {'Improvement':<15}\")\n",
    "print(f\"{'-'*60}\")\n",
    "\n",
    "# Note: Need to align test sets for fair comparison\n",
    "min_len = min(len(y_test), len(y_test_enh))\n",
    "original_r2 = metrics.r2_score(y_test[-min_len:], y_test_pred[-min_len:])\n",
    "enhanced_r2 = enhanced_metrics['R2']\n",
    "\n",
    "print(f\"R²{'':<13} {original_r2:<15.6f} {enhanced_r2:<15.6f} {enhanced_r2-original_r2:<15.6f}\")\n",
    "\n",
    "# Analyze volatility feature importance\n",
    "enhanced_coef = enhanced_pipeline.named_steps['regressor'].coef_\n",
    "volatility_coef = enhanced_coef[-1]  # Last coefficient is volatility\n",
    "\n",
    "print(f\"\\nVolatility Feature Analysis:\")\n",
    "print(f\"- Volatility coefficient: {volatility_coef:.6f}\")\n",
    "print(f\"- Volatility importance rank: {np.argsort(np.abs(enhanced_coef))[::-1].tolist().index(5) + 1} out of {len(enhanced_coef)}\")\n",
    "\n",
    "# Visualize volatility over time\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(enhanced_data.index[-100:], enhanced_data['Volatility_5d'][-100:], label='5-day Rolling Volatility')\n",
    "plt.title('5-Day Rolling Volatility (Last 100 days)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Volatility')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d08a7ac",
   "metadata": {},
   "source": [
    "### Exercise 3 Solution: Train/Test Split Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed14cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTRUCTOR ONLY - Exercise 3 Solution: Train/Test Split Analysis\n",
    "\n",
    "def train_with_split(X, y, train_ratio=0.8):\n",
    "    \"\"\"Train model with custom split ratio.\"\"\"\n",
    "    split_idx = int(train_ratio * len(X))\n",
    "    \n",
    "    # Chronological split\n",
    "    X_train_split = X.iloc[:split_idx]\n",
    "    X_test_split = X.iloc[split_idx:]\n",
    "    y_train_split = y.iloc[:split_idx]\n",
    "    y_test_split = y.iloc[split_idx:]\n",
    "    \n",
    "    # Train model\n",
    "    model = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', LinearRegression())\n",
    "    ])\n",
    "    \n",
    "    model.fit(X_train_split, y_train_split)\n",
    "    y_pred_split = model.predict(X_test_split)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = metrics.mean_squared_error(y_test_split, y_pred_split)\n",
    "    r2 = metrics.r2_score(y_test_split, y_pred_split)\n",
    "    \n",
    "    return {\n",
    "        'train_size': len(X_train_split),\n",
    "        'test_size': len(X_test_split),\n",
    "        'mse': mse,\n",
    "        'r2': r2,\n",
    "        'train_ratio': train_ratio\n",
    "    }\n",
    "\n",
    "# Test different splits\n",
    "split_ratios = [0.7, 0.8, 0.9]\n",
    "results = {}\n",
    "\n",
    "print(\"Training models with different train/test splits...\")\n",
    "for ratio in split_ratios:\n",
    "    results[ratio] = train_with_split(X, y, ratio)\n",
    "    print(f\"Split {ratio:.0%}: Train={results[ratio]['train_size']}, Test={results[ratio]['test_size']}\")\n",
    "\n",
    "# Create comparison table\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"TRAIN/TEST SPLIT COMPARISON\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"{'Split Ratio':<12} {'Train Size':<12} {'Test Size':<12} {'MSE':<12} {'R²':<12}\")\n",
    "print(f\"{'-'*70}\")\n",
    "\n",
    "for ratio in split_ratios:\n",
    "    r = results[ratio]\n",
    "    print(f\"{ratio:.0%}{'/'}{1-ratio:.0%:<8} {r['train_size']:<12} {r['test_size']:<12} {r['mse']:<12.6f} {r['r2']:<12.6f}\")\n",
    "\n",
    "# Visualize results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# MSE comparison\n",
    "ax1.bar([f\"{r:.0%}\" for r in split_ratios], [results[r]['mse'] for r in split_ratios], color='red', alpha=0.7)\n",
    "ax1.set_title('MSE by Train/Test Split Ratio')\n",
    "ax1.set_xlabel('Train Ratio')\n",
    "ax1.set_ylabel('MSE')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# R² comparison\n",
    "ax2.bar([f\"{r:.0%}\" for r in split_ratios], [results[r]['r2'] for r in split_ratios], color='blue', alpha=0.7)\n",
    "ax2.set_title('R² by Train/Test Split Ratio')\n",
    "ax2.set_xlabel('Train Ratio')\n",
    "ax2.set_ylabel('R²')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analysis and insights\n",
    "print(f\"\\nAnalysis of Split Ratio Effects:\")\n",
    "print(f\"1. More training data (90% split) generally leads to {'better' if results[0.9]['r2'] > results[0.7]['r2'] else 'similar'} performance\")\n",
    "print(f\"2. Smaller test sets (10%) may give {'less reliable' if results[0.9]['test_size'] < 50 else 'adequate'} performance estimates\")\n",
    "print(f\"3. The 80/20 split provides a good balance between training data and test set reliability\")\n",
    "\n",
    "best_ratio = max(split_ratios, key=lambda x: results[x]['r2'])\n",
    "print(f\"4. Best performing split: {best_ratio:.0%} train (R² = {results[best_ratio]['r2']:.6f})\")\n",
    "\n",
    "print(f\"\\nWhy split ratio matters in time series:\")\n",
    "print(f\"- More recent data in test set may have different patterns than older training data\")\n",
    "print(f\"- Market conditions change over time (concept drift)\")  \n",
    "print(f\"- Smaller test sets reduce statistical significance of performance metrics\")\n",
    "print(f\"- Too much training data may include outdated patterns\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
