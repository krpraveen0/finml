{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f6de1da",
   "metadata": {},
   "source": [
    "# Risk Modelling & Portfolio Optimization in Python\n",
    "**Week 5 - Financial ML Bootcamp (INSTRUCTOR VERSION)**\n",
    "\n",
    "## Overview\n",
    "This instructor notebook demonstrates risk modelling and portfolio optimization techniques with complete solutions and teaching notes.\n",
    "\n",
    "**Teaching Objectives:**\n",
    "- Guide students through Modern Portfolio Theory implementation\n",
    "- Explain Monte Carlo simulation intuition\n",
    "- Demonstrate VaR/CVaR practical applications\n",
    "- Show efficient frontier construction and interpretation\n",
    "\n",
    "**Instructor Notes:**\n",
    "- Emphasize diversification benefits through correlation analysis\n",
    "- Use visualizations to explain risk-return trade-offs\n",
    "- Connect theory to practical portfolio management\n",
    "- Highlight assumptions and limitations of MPT\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18f3a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters and Configuration\n",
    "SEED = 42\n",
    "SAMPLE_MODE = True  # Set to False for full analysis\n",
    "DATA_PATH = \"data/portfolio_assets.csv\"\n",
    "\n",
    "# Portfolio configuration\n",
    "ASSETS = ['AAPL', 'MSFT', 'GOOG', 'AMZN', 'META']\n",
    "START_DATE = '2019-01-01'\n",
    "END_DATE = '2024-01-01'\n",
    "NUM_PORTFOLIOS = 10000 if not SAMPLE_MODE else 1000\n",
    "CONFIDENCE_LEVEL = 0.95\n",
    "RISK_FREE_RATE = 0.02  # 2% annual risk-free rate\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"- Sample Mode: {SAMPLE_MODE}\")\n",
    "print(f\"- Assets: {ASSETS}\")\n",
    "print(f\"- Date Range: {START_DATE} to {END_DATE}\")\n",
    "print(f\"- Number of Portfolios: {NUM_PORTFOLIOS}\")\n",
    "print(f\"- Confidence Level: {CONFIDENCE_LEVEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a140f279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"âœ… Libraries imported successfully\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06300c6",
   "metadata": {},
   "source": [
    "## Step 1: Data Loading and Preprocessing\n",
    "\n",
    "**Teaching Notes:**\n",
    "- Explain why we use adjusted closing prices (accounts for dividends/splits)\n",
    "- Discuss the importance of sufficient historical data for reliable statistics\n",
    "- Highlight the trade-off between data length and relevance (older data may not reflect current market conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d839e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_portfolio_data(assets, start_date, end_date, sample_mode=True):\n",
    "    \"\"\"\n",
    "    Load historical price data for portfolio assets.\n",
    "    \n",
    "    INSTRUCTOR NOTE: This function includes robust error handling and fallback synthetic data\n",
    "    generation to ensure the notebook runs in all environments.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"ðŸ“Š Loading data for {len(assets)} assets...\")\n",
    "        \n",
    "        # Download data from Yahoo Finance\n",
    "        data = yf.download(assets, start=start_date, end=end_date, progress=False)\n",
    "        prices_df = data['Adj Close'].dropna()\n",
    "        \n",
    "        # Ensure we have data for all assets\n",
    "        if prices_df.empty or len(prices_df.columns) < len(assets):\n",
    "            raise ValueError(\"Incomplete data downloaded\")\n",
    "            \n",
    "        print(f\"âœ… Successfully loaded {len(prices_df)} days of data\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Data download failed: {e}\")\n",
    "        if sample_mode:\n",
    "            print(\"ðŸ”„ Generating synthetic data for demonstration...\")\n",
    "            prices_df = generate_synthetic_data(assets, start_date, end_date)\n",
    "        else:\n",
    "            raise\n",
    "    \n",
    "    # Calculate daily returns\n",
    "    returns_df = prices_df.pct_change().dropna()\n",
    "    \n",
    "    # Display basic statistics\n",
    "    print(f\"\\nData Summary:\")\n",
    "    print(f\"- Date range: {prices_df.index[0].strftime('%Y-%m-%d')} to {prices_df.index[-1].strftime('%Y-%m-%d')}\")\n",
    "    print(f\"- Number of trading days: {len(returns_df)}\")\n",
    "    print(f\"- Assets: {list(prices_df.columns)}\")\n",
    "    \n",
    "    return prices_df, returns_df\n",
    "\n",
    "def generate_synthetic_data(assets, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Generate synthetic price data for demonstration purposes.\n",
    "    \n",
    "    INSTRUCTOR NOTE: This creates realistic synthetic data with:\n",
    "    - Reasonable return/volatility parameters for tech stocks\n",
    "    - Positive correlations typical of same-sector assets\n",
    "    - Geometric Brownian motion price paths\n",
    "    \"\"\"\n",
    "    dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "    n_days = len(dates)\n",
    "    \n",
    "    # Synthetic parameters (realistic for tech stocks)\n",
    "    np.random.seed(SEED)\n",
    "    initial_prices = np.random.uniform(100, 300, len(assets))\n",
    "    annual_returns = np.random.uniform(0.05, 0.25, len(assets))\n",
    "    volatilities = np.random.uniform(0.15, 0.35, len(assets))\n",
    "    \n",
    "    # Generate correlated returns (tech stocks tend to be positively correlated)\n",
    "    base_correlation = 0.5\n",
    "    correlation_matrix = np.full((len(assets), len(assets)), base_correlation)\n",
    "    np.fill_diagonal(correlation_matrix, 1.0)\n",
    "    \n",
    "    # Add some randomness to correlations\n",
    "    for i in range(len(assets)):\n",
    "        for j in range(i+1, len(assets)):\n",
    "            correlation_matrix[i,j] = correlation_matrix[j,i] = np.random.uniform(0.3, 0.7)\n",
    "    \n",
    "    # Generate returns using multivariate normal distribution\n",
    "    daily_returns = np.random.multivariate_normal(\n",
    "        annual_returns / 252,  # Convert to daily\n",
    "        np.outer(volatilities, volatilities) * correlation_matrix / 252,\n",
    "        n_days\n",
    "    )\n",
    "    \n",
    "    # Convert to prices using geometric Brownian motion\n",
    "    prices = np.zeros((n_days, len(assets)))\n",
    "    prices[0] = initial_prices\n",
    "    \n",
    "    for i in range(1, n_days):\n",
    "        prices[i] = prices[i-1] * (1 + daily_returns[i])\n",
    "    \n",
    "    return pd.DataFrame(prices, index=dates, columns=assets)\n",
    "\n",
    "# Load the data\n",
    "prices_df, returns_df = load_portfolio_data(ASSETS, START_DATE, END_DATE, SAMPLE_MODE)\n",
    "\n",
    "# Display first few rows\n",
    "print(f\"\\nReturns Data (first 5 rows):\")\n",
    "print(returns_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f1c34b",
   "metadata": {},
   "source": [
    "## Step 2: Calculate Portfolio Statistics\n",
    "\n",
    "**Teaching Notes:**\n",
    "- Emphasize the difference between sample statistics and population parameters\n",
    "- Explain why we annualize returns and covariance (252 trading days convention)\n",
    "- Discuss the importance of correlation in portfolio construction\n",
    "- Point out that correlations can change over time (not constant as MPT assumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30de2236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_portfolio_stats(returns_df):\n",
    "    \"\"\"\n",
    "    Calculate portfolio statistics from returns data.\n",
    "    \n",
    "    INSTRUCTOR NOTE: We annualize using 252 trading days, which is the market standard.\n",
    "    Alternative approaches include 365 days or actual trading days in the period.\n",
    "    \"\"\"\n",
    "    # Annualize returns and covariance (252 trading days per year)\n",
    "    expected_returns = returns_df.mean() * 252\n",
    "    cov_matrix = returns_df.cov() * 252\n",
    "    correlation_matrix = returns_df.corr()\n",
    "    \n",
    "    return expected_returns, cov_matrix, correlation_matrix\n",
    "\n",
    "def display_portfolio_stats(expected_returns, cov_matrix, correlation_matrix):\n",
    "    \"\"\"Display portfolio statistics in a formatted way.\"\"\"\n",
    "    print(\"ðŸ“ˆ Portfolio Statistics Summary\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Expected returns\n",
    "    print(\"\\nðŸŽ¯ Expected Annual Returns:\")\n",
    "    for asset, ret in expected_returns.items():\n",
    "        print(f\"  {asset}: {ret:.2%}\")\n",
    "    \n",
    "    # Volatilities (standard deviations)\n",
    "    print(\"\\nðŸ“Š Annual Volatilities:\")\n",
    "    volatilities = np.sqrt(np.diag(cov_matrix))\n",
    "    for asset, vol in zip(expected_returns.index, volatilities):\n",
    "        print(f\"  {asset}: {vol:.2%}\")\n",
    "    \n",
    "    # Sharpe ratios (individual assets)\n",
    "    print(f\"\\nâš¡ Individual Sharpe Ratios (Risk-free rate: {RISK_FREE_RATE:.1%}):\")\n",
    "    for asset, ret, vol in zip(expected_returns.index, expected_returns, volatilities):\n",
    "        sharpe = (ret - RISK_FREE_RATE) / vol\n",
    "        print(f\"  {asset}: {sharpe:.3f}\")\n",
    "    \n",
    "    print(f\"\\nðŸ”— Correlation Matrix:\")\n",
    "    print(correlation_matrix.round(3))\n",
    "\n",
    "# Calculate portfolio statistics\n",
    "expected_returns, cov_matrix, correlation_matrix = calculate_portfolio_stats(returns_df)\n",
    "display_portfolio_stats(expected_returns, cov_matrix, correlation_matrix)\n",
    "\n",
    "# INSTRUCTOR ONLY: Additional analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸŽ“ INSTRUCTOR ANALYSIS: Correlation Insights\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Analyze correlation structure\n",
    "corr_values = correlation_matrix.values\n",
    "upper_triangle = corr_values[np.triu_indices_from(corr_values, k=1)]\n",
    "avg_correlation = np.mean(upper_triangle)\n",
    "min_correlation = np.min(upper_triangle)\n",
    "max_correlation = np.max(upper_triangle)\n",
    "\n",
    "print(f\"Average pairwise correlation: {avg_correlation:.3f}\")\n",
    "print(f\"Range: {min_correlation:.3f} to {max_correlation:.3f}\")\n",
    "print(f\"Interpretation: {'High' if avg_correlation > 0.7 else 'Moderate' if avg_correlation > 0.4 else 'Low'} correlation among assets\")\n",
    "\n",
    "# Diversification potential\n",
    "print(f\"\\nDiversification Potential:\")\n",
    "if avg_correlation > 0.7:\n",
    "    print(\"âš ï¸ High correlation - limited diversification benefits\")\n",
    "elif avg_correlation > 0.4:\n",
    "    print(\"âœ… Moderate correlation - good diversification potential\")\n",
    "else:\n",
    "    print(\"ðŸŽ¯ Low correlation - excellent diversification potential\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0808326",
   "metadata": {},
   "source": [
    "## Step 3: Monte Carlo Portfolio Simulation\n",
    "\n",
    "**Teaching Notes:**\n",
    "- Explain why we use random weights that sum to 1 (budget constraint)\n",
    "- Discuss the efficiency of Monte Carlo vs analytical methods\n",
    "- Emphasize that this explores the full risk-return space, not just the efficient frontier\n",
    "- Point out that most portfolios will be sub-optimal (inefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46b8488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_portfolios(expected_returns, cov_matrix, num_portfolios, risk_free_rate):\n",
    "    \"\"\"\n",
    "    Generate random portfolios using Monte Carlo simulation.\n",
    "    \n",
    "    INSTRUCTOR NOTE: This function demonstrates the Monte Carlo approach to portfolio\n",
    "    optimization. We generate random weights using uniform distribution, but other\n",
    "    approaches (e.g., Dirichlet distribution) could be used for different weight distributions.\n",
    "    \"\"\"\n",
    "    n_assets = len(expected_returns)\n",
    "    results = {\n",
    "        'returns': [],\n",
    "        'volatility': [],\n",
    "        'sharpe_ratio': [],\n",
    "        'weights': []\n",
    "    }\n",
    "    \n",
    "    print(f\"ðŸŽ² Generating {num_portfolios:,} random portfolios...\")\n",
    "    \n",
    "    # INSTRUCTOR NOTE: Using vectorized operations for efficiency\n",
    "    # Generate all random weights at once\n",
    "    all_weights = np.random.random((num_portfolios, n_assets))\n",
    "    all_weights = all_weights / np.sum(all_weights, axis=1, keepdims=True)\n",
    "    \n",
    "    for i in range(num_portfolios):\n",
    "        weights = all_weights[i]\n",
    "        \n",
    "        # Calculate portfolio return\n",
    "        portfolio_return = np.sum(expected_returns * weights)\n",
    "        \n",
    "        # Calculate portfolio volatility using matrix multiplication\n",
    "        portfolio_variance = np.dot(weights.T, np.dot(cov_matrix, weights))\n",
    "        portfolio_volatility = np.sqrt(portfolio_variance)\n",
    "        \n",
    "        # Calculate Sharpe ratio\n",
    "        sharpe_ratio = (portfolio_return - risk_free_rate) / portfolio_volatility\n",
    "        \n",
    "        # Store results\n",
    "        results['returns'].append(portfolio_return)\n",
    "        results['volatility'].append(portfolio_volatility)\n",
    "        results['sharpe_ratio'].append(sharpe_ratio)\n",
    "        results['weights'].append(weights)\n",
    "        \n",
    "        # Progress indicator\n",
    "        if (i + 1) % (num_portfolios // 10) == 0:\n",
    "            print(f\"  Progress: {((i + 1) / num_portfolios) * 100:.0f}%\")\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    for key in ['returns', 'volatility', 'sharpe_ratio']:\n",
    "        results[key] = np.array(results[key])\n",
    "    \n",
    "    print(f\"âœ… Generated {num_portfolios:,} portfolios\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Generate random portfolios\n",
    "portfolio_results = generate_random_portfolios(\n",
    "    expected_returns, cov_matrix, NUM_PORTFOLIOS, RISK_FREE_RATE\n",
    ")\n",
    "\n",
    "# Display summary statistics\n",
    "print(f\"\\nðŸ“Š Portfolio Simulation Results:\")\n",
    "print(f\"Returns - Min: {portfolio_results['returns'].min():.2%}, Max: {portfolio_results['returns'].max():.2%}\")\n",
    "print(f\"Volatility - Min: {portfolio_results['volatility'].min():.2%}, Max: {portfolio_results['volatility'].max():.2%}\")\n",
    "print(f\"Sharpe Ratio - Min: {portfolio_results['sharpe_ratio'].min():.3f}, Max: {portfolio_results['sharpe_ratio'].max():.3f}\")\n",
    "\n",
    "# INSTRUCTOR ONLY: Portfolio efficiency analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸŽ“ INSTRUCTOR ANALYSIS: Portfolio Efficiency\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "efficient_portfolios = portfolio_results['sharpe_ratio'] > 1.0\n",
    "pct_efficient = np.mean(efficient_portfolios) * 100\n",
    "print(f\"Portfolios with Sharpe > 1.0: {pct_efficient:.1f}%\")\n",
    "print(f\"This shows that most random portfolios are sub-optimal\")\n",
    "print(f\"Efficient portfolios are rare - highlighting the value of optimization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1691baeb",
   "metadata": {},
   "source": [
    "## Step 4: Identify Optimal Portfolio + Analytical Optimization\n",
    "\n",
    "**Teaching Notes:**\n",
    "- Compare Monte Carlo results with analytical optimization\n",
    "- Explain the difference between numerical and analytical solutions\n",
    "- Discuss when each approach is preferred\n",
    "- Highlight the efficiency gains from analytical methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befabe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTRUCTOR ONLY: Analytical Portfolio Optimization\n",
    "def analytical_portfolio_optimization(expected_returns, cov_matrix, risk_free_rate):\n",
    "    \"\"\"\n",
    "    Solve portfolio optimization analytically using scipy.optimize.\n",
    "    \n",
    "    INSTRUCTOR NOTE: This demonstrates the analytical approach to portfolio optimization,\n",
    "    which is more efficient and precise than Monte Carlo simulation.\n",
    "    \"\"\"\n",
    "    n_assets = len(expected_returns)\n",
    "    \n",
    "    # Objective function: minimize negative Sharpe ratio\n",
    "    def negative_sharpe_ratio(weights):\n",
    "        portfolio_return = np.sum(expected_returns * weights)\n",
    "        portfolio_variance = np.dot(weights.T, np.dot(cov_matrix, weights))\n",
    "        portfolio_volatility = np.sqrt(portfolio_variance)\n",
    "        return -(portfolio_return - risk_free_rate) / portfolio_volatility\n",
    "    \n",
    "    # Constraints: weights sum to 1\n",
    "    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "    \n",
    "    # Bounds: no short selling (weights >= 0)\n",
    "    bounds = tuple((0, 1) for _ in range(n_assets))\n",
    "    \n",
    "    # Initial guess: equal weights\n",
    "    initial_guess = np.array([1/n_assets] * n_assets)\n",
    "    \n",
    "    # Optimize\n",
    "    result = minimize(negative_sharpe_ratio, initial_guess, \n",
    "                     method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    \n",
    "    if result.success:\n",
    "        optimal_weights = result.x\n",
    "        portfolio_return = np.sum(expected_returns * optimal_weights)\n",
    "        portfolio_variance = np.dot(optimal_weights.T, np.dot(cov_matrix, optimal_weights))\n",
    "        portfolio_volatility = np.sqrt(portfolio_variance)\n",
    "        sharpe_ratio = (portfolio_return - risk_free_rate) / portfolio_volatility\n",
    "        \n",
    "        return {\n",
    "            'weights': optimal_weights,\n",
    "            'return': portfolio_return,\n",
    "            'volatility': portfolio_volatility,\n",
    "            'sharpe_ratio': sharpe_ratio,\n",
    "            'optimization_success': True\n",
    "        }\n",
    "    else:\n",
    "        return {'optimization_success': False}\n",
    "\n",
    "def find_optimal_portfolio(portfolio_results, expected_returns, assets):\n",
    "    \"\"\"Find the portfolio with maximum Sharpe ratio from Monte Carlo results.\"\"\"\n",
    "    # Find index of maximum Sharpe ratio\n",
    "    max_sharpe_idx = np.argmax(portfolio_results['sharpe_ratio'])\n",
    "    \n",
    "    # Extract optimal portfolio characteristics\n",
    "    optimal_portfolio = {\n",
    "        'weights': portfolio_results['weights'][max_sharpe_idx],\n",
    "        'return': portfolio_results['returns'][max_sharpe_idx],\n",
    "        'volatility': portfolio_results['volatility'][max_sharpe_idx],\n",
    "        'sharpe_ratio': portfolio_results['sharpe_ratio'][max_sharpe_idx]\n",
    "    }\n",
    "    \n",
    "    return optimal_portfolio, max_sharpe_idx\n",
    "\n",
    "def display_optimal_portfolio(optimal_portfolio, assets, method_name=\"Monte Carlo\"):\n",
    "    \"\"\"Display optimal portfolio characteristics.\"\"\"\n",
    "    print(f\"ðŸ† Optimal Portfolio - {method_name} Method\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Expected Return: {optimal_portfolio['return']:.2%}\")\n",
    "    print(f\"Volatility: {optimal_portfolio['volatility']:.2%}\")\n",
    "    print(f\"Sharpe Ratio: {optimal_portfolio['sharpe_ratio']:.3f}\")\n",
    "    \n",
    "    print(f\"\\nðŸ’¼ Portfolio Weights:\")\n",
    "    weights_df = pd.DataFrame({\n",
    "        'Asset': assets,\n",
    "        'Weight': optimal_portfolio['weights'],\n",
    "        'Weight %': optimal_portfolio['weights'] * 100\n",
    "    })\n",
    "    weights_df = weights_df.sort_values('Weight %', ascending=False)\n",
    "    \n",
    "    for _, row in weights_df.iterrows():\n",
    "        print(f\"  {row['Asset']}: {row['Weight %']:.1f}%\")\n",
    "    \n",
    "    return weights_df\n",
    "\n",
    "# Find optimal portfolio using Monte Carlo\n",
    "mc_optimal_portfolio, max_sharpe_idx = find_optimal_portfolio(portfolio_results, expected_returns, ASSETS)\n",
    "mc_weights_df = display_optimal_portfolio(mc_optimal_portfolio, ASSETS, \"Monte Carlo\")\n",
    "\n",
    "# INSTRUCTOR ONLY: Compare with analytical optimization\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸŽ“ INSTRUCTOR COMPARISON: Analytical vs Monte Carlo\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "analytical_result = analytical_portfolio_optimization(expected_returns, cov_matrix, RISK_FREE_RATE)\n",
    "\n",
    "if analytical_result['optimization_success']:\n",
    "    analytical_weights_df = display_optimal_portfolio(analytical_result, ASSETS, \"Analytical\")\n",
    "    \n",
    "    # Compare results\n",
    "    print(f\"\\nðŸ“Š Method Comparison:\")\n",
    "    print(f\"Monte Carlo Sharpe Ratio: {mc_optimal_portfolio['sharpe_ratio']:.6f}\")\n",
    "    print(f\"Analytical Sharpe Ratio: {analytical_result['sharpe_ratio']:.6f}\")\n",
    "    difference = analytical_result['sharpe_ratio'] - mc_optimal_portfolio['sharpe_ratio']\n",
    "    print(f\"Difference: {difference:.6f} ({difference/mc_optimal_portfolio['sharpe_ratio']*100:+.2f}%)\")\n",
    "    \n",
    "    # Weight comparison\n",
    "    print(f\"\\nðŸ’¼ Weight Comparison:\")\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'Asset': ASSETS,\n",
    "        'Monte Carlo': mc_optimal_portfolio['weights'] * 100,\n",
    "        'Analytical': analytical_result['weights'] * 100,\n",
    "        'Difference': (analytical_result['weights'] - mc_optimal_portfolio['weights']) * 100\n",
    "    })\n",
    "    comparison_df = comparison_df.round(2)\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ Teaching Point:\")\n",
    "    print(f\"Analytical optimization typically provides better results due to:\")\n",
    "    print(f\"  - Exact mathematical solution vs sampling approximation\")\n",
    "    print(f\"  - No dependence on random sampling\")\n",
    "    print(f\"  - Guaranteed global optimum for convex problems\")\n",
    "else:\n",
    "    print(\"âš ï¸ Analytical optimization failed\")\n",
    "\n",
    "# Use analytical result if available, otherwise Monte Carlo\n",
    "optimal_portfolio = analytical_result if analytical_result.get('optimization_success') else mc_optimal_portfolio\n",
    "weights_df = analytical_weights_df if analytical_result.get('optimization_success') else mc_weights_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c2d472",
   "metadata": {},
   "source": [
    "## Step 5: Advanced Visualization and Analysis\n",
    "\n",
    "**Teaching Notes:**\n",
    "- Use multiple visualization types to reinforce concepts\n",
    "- Explain the shape and curvature of the efficient frontier\n",
    "- Connect visual patterns to underlying mathematical relationships\n",
    "- Emphasize practical interpretation of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2916af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comprehensive_analysis(portfolio_results, optimal_portfolio, assets, \n",
    "                               expected_returns, cov_matrix, correlation_matrix):\n",
    "    \"\"\"\n",
    "    Create comprehensive visualizations for portfolio analysis.\n",
    "    \n",
    "    INSTRUCTOR NOTE: This enhanced visualization function provides multiple perspectives\n",
    "    on the portfolio optimization problem, helping students develop intuition.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    \n",
    "    # Create a complex subplot layout\n",
    "    gs = fig.add_gridspec(3, 3, height_ratios=[2, 1, 1], width_ratios=[2, 1, 1])\n",
    "    \n",
    "    # 1. Main Efficient Frontier (large plot)\n",
    "    ax_main = fig.add_subplot(gs[0, 0])\n",
    "    \n",
    "    # Color by Sharpe ratio\n",
    "    scatter = ax_main.scatter(portfolio_results['volatility'], portfolio_results['returns'], \n",
    "                             c=portfolio_results['sharpe_ratio'], cmap='viridis', \n",
    "                             alpha=0.6, s=20, edgecolors='none')\n",
    "    \n",
    "    # Highlight optimal portfolio\n",
    "    ax_main.scatter(optimal_portfolio['volatility'], optimal_portfolio['return'], \n",
    "                   marker='*', color='red', s=500, label='Optimal Portfolio',\n",
    "                   edgecolors='darkred', linewidth=2)\n",
    "    \n",
    "    # Plot individual assets\n",
    "    asset_volatilities = [np.sqrt(cov_matrix.loc[asset, asset]) for asset in assets]\n",
    "    ax_main.scatter(asset_volatilities, expected_returns, marker='D', s=150, \n",
    "                   color='orange', alpha=0.9, label='Individual Assets',\n",
    "                   edgecolors='darkorange', linewidth=2)\n",
    "    \n",
    "    # Add asset labels with better positioning\n",
    "    for i, asset in enumerate(assets):\n",
    "        ax_main.annotate(asset, (asset_volatilities[i], expected_returns[i]), \n",
    "                        xytext=(10, 10), textcoords='offset points', \n",
    "                        fontsize=10, fontweight='bold',\n",
    "                        bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    ax_main.set_xlabel('Portfolio Volatility (Risk)', fontsize=12)\n",
    "    ax_main.set_ylabel('Expected Return', fontsize=12)\n",
    "    ax_main.set_title('Efficient Frontier Analysis\\nRisk vs Return Trade-off', fontsize=14, fontweight='bold')\n",
    "    ax_main.legend(fontsize=10)\n",
    "    ax_main.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(scatter, ax=ax_main)\n",
    "    cbar.set_label('Sharpe Ratio', fontsize=10)\n",
    "    \n",
    "    # 2. Sharpe Ratio Distribution\n",
    "    ax_sharpe = fig.add_subplot(gs[0, 1])\n",
    "    ax_sharpe.hist(portfolio_results['sharpe_ratio'], bins=50, alpha=0.7, \n",
    "                  color='skyblue', edgecolor='black', density=True)\n",
    "    ax_sharpe.axvline(optimal_portfolio['sharpe_ratio'], color='red', linestyle='--', \n",
    "                     linewidth=2, label=f'Optimal: {optimal_portfolio[\"sharpe_ratio\"]:.3f}')\n",
    "    ax_sharpe.set_xlabel('Sharpe Ratio')\n",
    "    ax_sharpe.set_ylabel('Density')\n",
    "    ax_sharpe.set_title('Sharpe Ratio\\nDistribution')\n",
    "    ax_sharpe.legend()\n",
    "    ax_sharpe.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Portfolio Weights (Optimal)\n",
    "    ax_weights = fig.add_subplot(gs[0, 2])\n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(assets)))\n",
    "    wedges, texts, autotexts = ax_weights.pie(optimal_portfolio['weights'], \n",
    "                                             labels=assets, autopct='%1.1f%%', \n",
    "                                             colors=colors, startangle=90)\n",
    "    ax_weights.set_title('Optimal Portfolio\\nWeights')\n",
    "    \n",
    "    # 4. Correlation Heatmap\n",
    "    ax_corr = fig.add_subplot(gs[1, 0])\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='RdYlBu_r', center=0,\n",
    "                square=True, ax=ax_corr, cbar_kws={'shrink': 0.8})\n",
    "    ax_corr.set_title('Asset Correlation Matrix')\n",
    "    \n",
    "    # 5. Risk-Return by Asset\n",
    "    ax_risk_return = fig.add_subplot(gs[1, 1])\n",
    "    volatilities = [np.sqrt(cov_matrix.loc[asset, asset]) for asset in assets]\n",
    "    bars = ax_risk_return.bar(range(len(assets)), expected_returns, \n",
    "                             alpha=0.7, color='lightgreen', label='Expected Return')\n",
    "    ax_risk_return2 = ax_risk_return.twinx()\n",
    "    bars2 = ax_risk_return2.bar([i+0.4 for i in range(len(assets))], volatilities, \n",
    "                               alpha=0.7, color='lightcoral', width=0.4, label='Volatility')\n",
    "    \n",
    "    ax_risk_return.set_xlabel('Assets')\n",
    "    ax_risk_return.set_ylabel('Expected Return', color='green')\n",
    "    ax_risk_return2.set_ylabel('Volatility', color='red')\n",
    "    ax_risk_return.set_xticks(range(len(assets)))\n",
    "    ax_risk_return.set_xticklabels(assets, rotation=45)\n",
    "    ax_risk_return.set_title('Individual Asset\\nRisk-Return Profile')\n",
    "    \n",
    "    # 6. Weight Distribution Analysis\n",
    "    ax_weight_dist = fig.add_subplot(gs[1, 2])\n",
    "    optimal_weights_pct = optimal_portfolio['weights'] * 100\n",
    "    ax_weight_dist.barh(assets, optimal_weights_pct, color=colors)\n",
    "    ax_weight_dist.set_xlabel('Weight (%)')\n",
    "    ax_weight_dist.set_title('Portfolio Weight\\nDistribution')\n",
    "    ax_weight_dist.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 7. Efficient Frontier Zoom (bottom left)\n",
    "    ax_ef_zoom = fig.add_subplot(gs[2, 0])\n",
    "    # Focus on efficient portfolios (high Sharpe ratios)\n",
    "    efficient_mask = portfolio_results['sharpe_ratio'] > np.percentile(portfolio_results['sharpe_ratio'], 90)\n",
    "    ax_ef_zoom.scatter(portfolio_results['volatility'][efficient_mask], \n",
    "                      portfolio_results['returns'][efficient_mask],\n",
    "                      c=portfolio_results['sharpe_ratio'][efficient_mask], \n",
    "                      cmap='viridis', alpha=0.8, s=30)\n",
    "    ax_ef_zoom.scatter(optimal_portfolio['volatility'], optimal_portfolio['return'], \n",
    "                      marker='*', color='red', s=200)\n",
    "    ax_ef_zoom.set_xlabel('Volatility')\n",
    "    ax_ef_zoom.set_ylabel('Return')\n",
    "    ax_ef_zoom.set_title('Efficient Frontier\\n(Top 10% Sharpe Ratios)')\n",
    "    ax_ef_zoom.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 8. Statistics Summary Table\n",
    "    ax_stats = fig.add_subplot(gs[2, 1:])\n",
    "    ax_stats.axis('off')\n",
    "    \n",
    "    # Create summary statistics\n",
    "    stats_data = [\n",
    "        ['Metric', 'Value', 'Interpretation'],\n",
    "        ['Expected Return', f\"{optimal_portfolio['return']:.2%}\", 'Annual expected return'],\n",
    "        ['Volatility', f\"{optimal_portfolio['volatility']:.2%}\", 'Annual risk (std deviation)'],\n",
    "        ['Sharpe Ratio', f\"{optimal_portfolio['sharpe_ratio']:.3f}\", 'Risk-adjusted return'],\n",
    "        ['Max Weight', f\"{max(optimal_portfolio['weights'])*100:.1f}%\", 'Largest single allocation'],\n",
    "        ['Min Weight', f\"{min(optimal_portfolio['weights'])*100:.1f}%\", 'Smallest allocation'],\n",
    "        ['Diversification', f\"{len([w for w in optimal_portfolio['weights'] if w > 0.05])}\", 'Assets with >5% allocation']\n",
    "    ]\n",
    "    \n",
    "    table = ax_stats.table(cellText=stats_data[1:], colLabels=stats_data[0],\n",
    "                          cellLoc='center', loc='center', \n",
    "                          colWidths=[0.3, 0.2, 0.5])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1, 2)\n",
    "    \n",
    "    # Style the table\n",
    "    for i in range(len(stats_data)):\n",
    "        for j in range(len(stats_data[0])):\n",
    "            cell = table[(i, j)]\n",
    "            if i == 0:  # Header row\n",
    "                cell.set_facecolor('#4472C4')\n",
    "                cell.set_text_props(weight='bold', color='white')\n",
    "            else:\n",
    "                cell.set_facecolor('#F2F2F2' if i % 2 == 0 else 'white')\n",
    "    \n",
    "    plt.suptitle('Comprehensive Portfolio Analysis Dashboard', fontsize=16, fontweight='bold', y=0.98)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.94)\n",
    "    plt.show()\n",
    "\n",
    "# Create comprehensive visualization\n",
    "plot_comprehensive_analysis(portfolio_results, optimal_portfolio, ASSETS, \n",
    "                           expected_returns, cov_matrix, correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbd31d5",
   "metadata": {},
   "source": [
    "## Step 6: VaR and CVaR with Advanced Methods\n",
    "\n",
    "**Teaching Notes:**\n",
    "- Compare different VaR calculation methods (historical, parametric, Monte Carlo)\n",
    "- Explain the assumptions behind each approach\n",
    "- Discuss the advantages and limitations of each method\n",
    "- Emphasize the importance of backtesting VaR models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e5945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_comprehensive_var_cvar(weights, returns_df, confidence_level=0.95, \n",
    "                                   time_horizon=1, num_simulations=10000):\n",
    "    \"\"\"\n",
    "    Calculate VaR and CVaR using multiple methods for comparison.\n",
    "    \n",
    "    INSTRUCTOR NOTE: This function demonstrates three common approaches to VaR calculation:\n",
    "    1. Historical Simulation (non-parametric)\n",
    "    2. Parametric (assumes normal distribution)\n",
    "    3. Monte Carlo (simulation-based)\n",
    "    \"\"\"\n",
    "    print(f\"ðŸŽ¯ Comprehensive VaR/CVaR Analysis\")\n",
    "    print(f\"=\" * 50)\n",
    "    print(f\"Confidence Level: {confidence_level:.1%}\")\n",
    "    print(f\"Time Horizon: {time_horizon} day(s)\")\n",
    "    \n",
    "    # Calculate portfolio returns\n",
    "    portfolio_returns = (returns_df * weights).sum(axis=1)\n",
    "    \n",
    "    # Method 1: Historical Simulation\n",
    "    print(f\"\\nðŸ“Š Method 1: Historical Simulation\")\n",
    "    historical_returns = portfolio_returns * np.sqrt(time_horizon)  # Scale for time horizon\n",
    "    alpha = 1 - confidence_level\n",
    "    var_historical = np.percentile(historical_returns, alpha * 100)\n",
    "    cvar_historical = historical_returns[historical_returns <= var_historical].mean()\n",
    "    \n",
    "    print(f\"  Historical VaR: {var_historical:.2%}\")\n",
    "    print(f\"  Historical CVaR: {cvar_historical:.2%}\")\n",
    "    \n",
    "    # Method 2: Parametric (Normal Distribution)\n",
    "    print(f\"\\nðŸ“ Method 2: Parametric (Normal)\")\n",
    "    mean_return = portfolio_returns.mean() * time_horizon\n",
    "    std_return = portfolio_returns.std() * np.sqrt(time_horizon)\n",
    "    var_parametric = norm.ppf(alpha, mean_return, std_return)\n",
    "    # For normal distribution, CVaR has analytical formula\n",
    "    cvar_parametric = mean_return - std_return * norm.pdf(norm.ppf(alpha)) / alpha\n",
    "    \n",
    "    print(f\"  Parametric VaR: {var_parametric:.2%}\")\n",
    "    print(f\"  Parametric CVaR: {cvar_parametric:.2%}\")\n",
    "    \n",
    "    # Method 3: Monte Carlo Simulation\n",
    "    print(f\"\\nðŸŽ² Method 3: Monte Carlo Simulation\")\n",
    "    np.random.seed(SEED)\n",
    "    simulated_returns = np.random.normal(mean_return, std_return, num_simulations)\n",
    "    var_monte_carlo = np.percentile(simulated_returns, alpha * 100)\n",
    "    cvar_monte_carlo = simulated_returns[simulated_returns <= var_monte_carlo].mean()\n",
    "    \n",
    "    print(f\"  Monte Carlo VaR: {var_monte_carlo:.2%}\")\n",
    "    print(f\"  Monte Carlo CVaR: {cvar_monte_carlo:.2%}\")\n",
    "    \n",
    "    # INSTRUCTOR ONLY: Method comparison and analysis\n",
    "    print(f\"\\n\" + \"=\"*50)\n",
    "    print(f\"ðŸŽ“ INSTRUCTOR ANALYSIS: Method Comparison\")\n",
    "    print(f\"=\"*50)\n",
    "    \n",
    "    methods_comparison = pd.DataFrame({\n",
    "        'Method': ['Historical', 'Parametric', 'Monte Carlo'],\n",
    "        'VaR': [var_historical, var_parametric, var_monte_carlo],\n",
    "        'CVaR': [cvar_historical, cvar_parametric, cvar_monte_carlo]\n",
    "    })\n",
    "    methods_comparison['VaR %'] = methods_comparison['VaR'] * 100\n",
    "    methods_comparison['CVaR %'] = methods_comparison['CVaR'] * 100\n",
    "    \n",
    "    print(\"VaR/CVaR Comparison:\")\n",
    "    print(methods_comparison[['Method', 'VaR %', 'CVaR %']].round(2).to_string(index=False))\n",
    "    \n",
    "    # Calculate differences\n",
    "    var_range = methods_comparison['VaR'].max() - methods_comparison['VaR'].min()\n",
    "    cvar_range = methods_comparison['CVaR'].max() - methods_comparison['CVaR'].min()\n",
    "    \n",
    "    print(f\"\\nMethod Sensitivity:\")\n",
    "    print(f\"VaR range: {var_range:.2%} ({var_range/abs(methods_comparison['VaR'].mean())*100:.1f}% relative)\")\n",
    "    print(f\"CVaR range: {cvar_range:.2%} ({cvar_range/abs(methods_comparison['CVaR'].mean())*100:.1f}% relative)\")\n",
    "    \n",
    "    # Interpretation\n",
    "    print(f\"\\nðŸ” Method Interpretation:\")\n",
    "    print(f\"Historical: Uses actual past data - good for capturing real market behavior\")\n",
    "    print(f\"Parametric: Assumes normality - fast but may underestimate tail risk\")\n",
    "    print(f\"Monte Carlo: Flexible - can incorporate complex return distributions\")\n",
    "    \n",
    "    return {\n",
    "        'historical': {'var': var_historical, 'cvar': cvar_historical},\n",
    "        'parametric': {'var': var_parametric, 'cvar': cvar_parametric},\n",
    "        'monte_carlo': {'var': var_monte_carlo, 'cvar': cvar_monte_carlo},\n",
    "        'simulated_returns': simulated_returns,\n",
    "        'historical_returns': historical_returns,\n",
    "        'comparison_df': methods_comparison\n",
    "    }\n",
    "\n",
    "def plot_var_cvar_comprehensive(var_results, confidence_level):\n",
    "    \"\"\"\n",
    "    Create comprehensive VaR/CVaR visualizations comparing different methods.\n",
    "    \n",
    "    INSTRUCTOR NOTE: This visualization helps students understand the differences\n",
    "    between VaR calculation methods and their practical implications.\n",
    "    \"\"\"\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Distribution comparison with VaR lines\n",
    "    ax1.hist(var_results['historical_returns'], bins=50, alpha=0.6, \n",
    "            label='Historical Returns', density=True, color='skyblue')\n",
    "    ax1.hist(var_results['simulated_returns'], bins=50, alpha=0.6, \n",
    "            label='Simulated Returns', density=True, color='lightcoral')\n",
    "    \n",
    "    # Add VaR lines\n",
    "    colors = ['blue', 'green', 'red']\n",
    "    methods = ['Historical', 'Parametric', 'Monte Carlo']\n",
    "    vars = [var_results['historical']['var'], \n",
    "            var_results['parametric']['var'], \n",
    "            var_results['monte_carlo']['var']]\n",
    "    \n",
    "    for i, (method, var_val, color) in enumerate(zip(methods, vars, colors)):\n",
    "        ax1.axvline(var_val, color=color, linestyle='--', linewidth=2, \n",
    "                   label=f'{method} VaR')\n",
    "    \n",
    "    ax1.set_xlabel('Portfolio Returns')\n",
    "    ax1.set_ylabel('Density')\n",
    "    ax1.set_title(f'Return Distributions with VaR ({confidence_level:.0%})')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. VaR Method Comparison\n",
    "    methods = var_results['comparison_df']['Method']\n",
    "    var_values = var_results['comparison_df']['VaR %']\n",
    "    cvar_values = var_results['comparison_df']['CVaR %']\n",
    "    \n",
    "    x = np.arange(len(methods))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = ax2.bar(x - width/2, var_values, width, label='VaR', alpha=0.8, color='lightblue')\n",
    "    bars2 = ax2.bar(x + width/2, cvar_values, width, label='CVaR', alpha=0.8, color='lightcoral')\n",
    "    \n",
    "    ax2.set_xlabel('Method')\n",
    "    ax2.set_ylabel('Value (%)')\n",
    "    ax2.set_title('VaR vs CVaR by Method')\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(methods)\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars1 + bars2:\n",
    "        height = bar.get_height()\n",
    "        ax2.annotate(f'{height:.1f}%',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3), textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # 3. Tail Risk Analysis\n",
    "    tail_threshold = var_results['monte_carlo']['var']\n",
    "    tail_returns = var_results['simulated_returns'][var_results['simulated_returns'] <= tail_threshold]\n",
    "    \n",
    "    ax3.hist(var_results['simulated_returns'], bins=100, alpha=0.6, color='lightblue', \n",
    "            density=True, label='All Returns')\n",
    "    ax3.hist(tail_returns, bins=30, alpha=0.8, color='red', density=True, \n",
    "            label=f'Tail Risk ({100-confidence_level*100:.0f}%)')\n",
    "    ax3.axvline(tail_threshold, color='red', linestyle='--', linewidth=2, label='VaR Threshold')\n",
    "    ax3.axvline(var_results['monte_carlo']['cvar'], color='darkred', linestyle='--', \n",
    "               linewidth=2, label='CVaR (Expected Tail Loss)')\n",
    "    \n",
    "    ax3.set_xlabel('Portfolio Returns')\n",
    "    ax3.set_ylabel('Density')\n",
    "    ax3.set_title('Tail Risk Analysis')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Cumulative Distribution with Risk Measures\n",
    "    sorted_returns = np.sort(var_results['simulated_returns'])\n",
    "    probabilities = np.arange(1, len(sorted_returns) + 1) / len(sorted_returns)\n",
    "    \n",
    "    ax4.plot(sorted_returns, probabilities, color='blue', linewidth=2, label='Cumulative Distribution')\n",
    "    ax4.axvline(var_results['monte_carlo']['var'], color='red', linestyle='--', \n",
    "               linewidth=2, label=f'VaR ({confidence_level:.0%})')\n",
    "    ax4.axhline(1 - confidence_level, color='red', linestyle=':', alpha=0.7, \n",
    "               label=f'{confidence_level:.0%} Confidence Level')\n",
    "    \n",
    "    # Shade the tail area\n",
    "    tail_mask = sorted_returns <= var_results['monte_carlo']['var']\n",
    "    ax4.fill_between(sorted_returns[tail_mask], 0, probabilities[tail_mask], \n",
    "                    alpha=0.3, color='red', label='Tail Risk Area')\n",
    "    \n",
    "    ax4.set_xlabel('Portfolio Returns')\n",
    "    ax4.set_ylabel('Cumulative Probability')\n",
    "    ax4.set_title('Cumulative Distribution with Risk Measures')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Calculate comprehensive VaR/CVaR\n",
    "var_results = calculate_comprehensive_var_cvar(\n",
    "    optimal_portfolio['weights'], returns_df, CONFIDENCE_LEVEL, \n",
    "    time_horizon=1, num_simulations=10000 if not SAMPLE_MODE else 5000\n",
    ")\n",
    "\n",
    "# Create comprehensive visualization\n",
    "plot_var_cvar_comprehensive(var_results, CONFIDENCE_LEVEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cb1aba",
   "metadata": {},
   "source": [
    "## INSTRUCTOR SOLUTIONS: Exercise Implementations\n",
    "\n",
    "**Teaching Notes:**\n",
    "- These solutions demonstrate advanced portfolio optimization techniques\n",
    "- Show students how to implement constraints and different objective functions\n",
    "- Explain the trade-offs between different optimization approaches\n",
    "- Discuss practical considerations for real-world implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514fe5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTRUCTOR SOLUTION 1: Risk-Free Asset Integration\n",
    "print(\"ðŸŽ“ INSTRUCTOR SOLUTION 1: Risk-Free Asset Integration\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def add_risk_free_asset(expected_returns, cov_matrix, risk_free_rate):\n",
    "    \"\"\"\n",
    "    Add a risk-free asset to the portfolio universe.\n",
    "    \n",
    "    INSTRUCTOR NOTE: Adding a risk-free asset changes the efficient frontier from\n",
    "    a curve to a straight line (Capital Allocation Line) for portfolios that include\n",
    "    the risk-free asset.\n",
    "    \"\"\"\n",
    "    # Create new expected returns including risk-free asset\n",
    "    rf_returns = expected_returns.copy()\n",
    "    rf_returns['RF'] = risk_free_rate\n",
    "    \n",
    "    # Create new covariance matrix (risk-free asset has zero covariance with everything)\n",
    "    rf_cov = cov_matrix.copy()\n",
    "    rf_cov['RF'] = 0\n",
    "    rf_cov.loc['RF'] = 0\n",
    "    rf_cov.loc['RF', 'RF'] = 0  # Risk-free asset has zero variance\n",
    "    \n",
    "    return rf_returns, rf_cov\n",
    "\n",
    "def optimize_with_risk_free_asset(expected_returns, cov_matrix, risk_free_rate):\n",
    "    \"\"\"Optimize portfolio including risk-free asset.\"\"\"\n",
    "    rf_returns, rf_cov = add_risk_free_asset(expected_returns, cov_matrix, risk_free_rate)\n",
    "    n_assets = len(rf_returns)\n",
    "    \n",
    "    def negative_sharpe_ratio(weights):\n",
    "        portfolio_return = np.sum(rf_returns * weights)\n",
    "        portfolio_variance = np.dot(weights.T, np.dot(rf_cov, weights))\n",
    "        portfolio_volatility = np.sqrt(portfolio_variance)\n",
    "        # Avoid division by zero\n",
    "        if portfolio_volatility == 0:\n",
    "            return -np.inf\n",
    "        return -(portfolio_return - risk_free_rate) / portfolio_volatility\n",
    "    \n",
    "    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "    bounds = tuple((0, 1) for _ in range(n_assets))\n",
    "    initial_guess = np.array([1/n_assets] * n_assets)\n",
    "    \n",
    "    result = minimize(negative_sharpe_ratio, initial_guess, \n",
    "                     method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    \n",
    "    if result.success:\n",
    "        return {\n",
    "            'weights': result.x,\n",
    "            'assets': list(rf_returns.index),\n",
    "            'returns': rf_returns,\n",
    "            'success': True\n",
    "        }\n",
    "    return {'success': False}\n",
    "\n",
    "# Implement risk-free asset solution\n",
    "rf_solution = optimize_with_risk_free_asset(expected_returns, cov_matrix, RISK_FREE_RATE)\n",
    "\n",
    "if rf_solution['success']:\n",
    "    print(\"Portfolio with Risk-Free Asset:\")\n",
    "    for i, (asset, weight) in enumerate(zip(rf_solution['assets'], rf_solution['weights'])):\n",
    "        if weight > 0.001:  # Only show significant weights\n",
    "            print(f\"  {asset}: {weight*100:.1f}%\")\n",
    "    \n",
    "    rf_weight = rf_solution['weights'][-1]  # Risk-free asset is last\n",
    "    print(f\"\\nRisk-Free Asset Allocation: {rf_weight*100:.1f}%\")\n",
    "    print(f\"Risky Asset Allocation: {(1-rf_weight)*100:.1f}%\")\n",
    "else:\n",
    "    print(\"âŒ Risk-free asset optimization failed\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸŽ“ INSTRUCTOR SOLUTION 2: Constrained Optimization\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def optimize_with_constraints(expected_returns, cov_matrix, risk_free_rate, \n",
    "                            min_weight=0.05, max_weight=0.40):\n",
    "    \"\"\"\n",
    "    Optimize portfolio with realistic constraints.\n",
    "    \n",
    "    INSTRUCTOR NOTE: Real-world portfolios often have constraints:\n",
    "    - No short selling (min_weight >= 0)\n",
    "    - Diversification requirements (max_weight <= threshold)\n",
    "    - Minimum allocations (min_weight >= threshold)\n",
    "    \"\"\"\n",
    "    n_assets = len(expected_returns)\n",
    "    \n",
    "    def negative_sharpe_ratio(weights):\n",
    "        portfolio_return = np.sum(expected_returns * weights)\n",
    "        portfolio_variance = np.dot(weights.T, np.dot(cov_matrix, weights))\n",
    "        portfolio_volatility = np.sqrt(portfolio_variance)\n",
    "        return -(portfolio_return - risk_free_rate) / portfolio_volatility\n",
    "    \n",
    "    # Constraints\n",
    "    constraints = [\n",
    "        {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}  # Weights sum to 1\n",
    "    ]\n",
    "    \n",
    "    # Bounds: minimum and maximum weights\n",
    "    bounds = tuple((min_weight, max_weight) for _ in range(n_assets))\n",
    "    \n",
    "    # Initial guess: equal weights within bounds\n",
    "    initial_weight = 1 / n_assets\n",
    "    if initial_weight < min_weight:\n",
    "        initial_weight = min_weight\n",
    "    elif initial_weight > max_weight:\n",
    "        initial_weight = max_weight\n",
    "    \n",
    "    initial_guess = np.array([initial_weight] * n_assets)\n",
    "    initial_guess = initial_guess / np.sum(initial_guess)  # Normalize\n",
    "    \n",
    "    result = minimize(negative_sharpe_ratio, initial_guess, \n",
    "                     method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    \n",
    "    if result.success:\n",
    "        optimal_weights = result.x\n",
    "        portfolio_return = np.sum(expected_returns * optimal_weights)\n",
    "        portfolio_variance = np.dot(optimal_weights.T, np.dot(cov_matrix, optimal_weights))\n",
    "        portfolio_volatility = np.sqrt(portfolio_variance)\n",
    "        sharpe_ratio = (portfolio_return - risk_free_rate) / portfolio_volatility\n",
    "        \n",
    "        return {\n",
    "            'weights': optimal_weights,\n",
    "            'return': portfolio_return,\n",
    "            'volatility': portfolio_volatility,\n",
    "            'sharpe_ratio': sharpe_ratio,\n",
    "            'success': True\n",
    "        }\n",
    "    return {'success': False}\n",
    "\n",
    "# Implement constrained optimization\n",
    "constrained_solution = optimize_with_constraints(expected_returns, cov_matrix, RISK_FREE_RATE)\n",
    "\n",
    "if constrained_solution['success']:\n",
    "    print(\"Constrained Portfolio (5%-40% per asset):\")\n",
    "    constrained_df = pd.DataFrame({\n",
    "        'Asset': ASSETS,\n",
    "        'Weight': constrained_solution['weights'],\n",
    "        'Weight %': constrained_solution['weights'] * 100\n",
    "    }).sort_values('Weight %', ascending=False)\n",
    "    \n",
    "    for _, row in constrained_df.iterrows():\n",
    "        print(f\"  {row['Asset']}: {row['Weight %']:.1f}%\")\n",
    "    \n",
    "    print(f\"\\nConstrained Portfolio Metrics:\")\n",
    "    print(f\"  Expected Return: {constrained_solution['return']:.2%}\")\n",
    "    print(f\"  Volatility: {constrained_solution['volatility']:.2%}\")\n",
    "    print(f\"  Sharpe Ratio: {constrained_solution['sharpe_ratio']:.3f}\")\n",
    "    \n",
    "    # Compare with unconstrained\n",
    "    print(f\"\\nComparison with Unconstrained:\")\n",
    "    print(f\"  Sharpe Ratio Difference: {constrained_solution['sharpe_ratio'] - optimal_portfolio['sharpe_ratio']:.3f}\")\n",
    "    if constrained_solution['sharpe_ratio'] < optimal_portfolio['sharpe_ratio']:\n",
    "        loss = (optimal_portfolio['sharpe_ratio'] - constrained_solution['sharpe_ratio']) / optimal_portfolio['sharpe_ratio']\n",
    "        print(f\"  Performance Loss: {loss*100:.1f}%\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ Constrained optimization failed\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸŽ“ INSTRUCTOR SOLUTION 3: Multiple Objective Functions\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def optimize_multiple_objectives(expected_returns, cov_matrix, risk_free_rate):\n",
    "    \"\"\"\n",
    "    Demonstrate different optimization objectives.\n",
    "    \n",
    "    INSTRUCTOR NOTE: Different objectives lead to different optimal portfolios:\n",
    "    - Max Sharpe: Best risk-adjusted return\n",
    "    - Min Variance: Lowest risk\n",
    "    - Max Return: Highest return (subject to risk constraint)\n",
    "    \"\"\"\n",
    "    n_assets = len(expected_returns)\n",
    "    \n",
    "    # 1. Maximum Sharpe Ratio (already done)\n",
    "    max_sharpe = optimal_portfolio\n",
    "    \n",
    "    # 2. Minimum Variance Portfolio\n",
    "    def portfolio_variance(weights):\n",
    "        return np.dot(weights.T, np.dot(cov_matrix, weights))\n",
    "    \n",
    "    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "    bounds = tuple((0, 1) for _ in range(n_assets))\n",
    "    initial_guess = np.array([1/n_assets] * n_assets)\n",
    "    \n",
    "    min_var_result = minimize(portfolio_variance, initial_guess, \n",
    "                             method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    \n",
    "    if min_var_result.success:\n",
    "        min_var_weights = min_var_result.x\n",
    "        min_var_return = np.sum(expected_returns * min_var_weights)\n",
    "        min_var_volatility = np.sqrt(portfolio_variance(min_var_weights))\n",
    "        min_var_sharpe = (min_var_return - risk_free_rate) / min_var_volatility\n",
    "        \n",
    "        min_var_portfolio = {\n",
    "            'weights': min_var_weights,\n",
    "            'return': min_var_return,\n",
    "            'volatility': min_var_volatility,\n",
    "            'sharpe_ratio': min_var_sharpe\n",
    "        }\n",
    "    \n",
    "    # 3. Maximum Return Portfolio (equal weights for comparison)\n",
    "    equal_weights = np.array([1/n_assets] * n_assets)\n",
    "    equal_return = np.sum(expected_returns * equal_weights)\n",
    "    equal_variance = np.dot(equal_weights.T, np.dot(cov_matrix, equal_weights))\n",
    "    equal_volatility = np.sqrt(equal_variance)\n",
    "    equal_sharpe = (equal_return - risk_free_rate) / equal_volatility\n",
    "    \n",
    "    equal_portfolio = {\n",
    "        'weights': equal_weights,\n",
    "        'return': equal_return,\n",
    "        'volatility': equal_volatility,\n",
    "        'sharpe_ratio': equal_sharpe\n",
    "    }\n",
    "    \n",
    "    # Create comparison\n",
    "    objectives_df = pd.DataFrame({\n",
    "        'Objective': ['Max Sharpe', 'Min Variance', 'Equal Weights'],\n",
    "        'Return': [max_sharpe['return'], min_var_portfolio['return'], equal_portfolio['return']],\n",
    "        'Volatility': [max_sharpe['volatility'], min_var_portfolio['volatility'], equal_portfolio['volatility']],\n",
    "        'Sharpe': [max_sharpe['sharpe_ratio'], min_var_portfolio['sharpe_ratio'], equal_portfolio['sharpe_ratio']]\n",
    "    })\n",
    "    \n",
    "    print(\"Portfolio Comparison by Objective:\")\n",
    "    print(objectives_df.round(4).to_string(index=False))\n",
    "    \n",
    "    return {\n",
    "        'max_sharpe': max_sharpe,\n",
    "        'min_variance': min_var_portfolio,\n",
    "        'equal_weights': equal_portfolio,\n",
    "        'comparison': objectives_df\n",
    "    }\n",
    "\n",
    "# Implement multiple objectives comparison\n",
    "multi_obj_results = optimize_multiple_objectives(expected_returns, cov_matrix, RISK_FREE_RATE)\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Key Teaching Points:\")\n",
    "print(f\"1. Max Sharpe provides best risk-adjusted returns\")\n",
    "print(f\"2. Min Variance provides lowest risk but may sacrifice returns\")\n",
    "print(f\"3. Equal weights is simple but usually sub-optimal\")\n",
    "print(f\"4. Choice depends on investor risk tolerance and objectives\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3629544d",
   "metadata": {},
   "source": [
    "## Summary and Advanced Topics\n",
    "\n",
    "**Teaching Summary:**\n",
    "This notebook demonstrates the complete portfolio optimization workflow using Modern Portfolio Theory. Students have learned to:\n",
    "\n",
    "1. **Load and process financial data** with robust error handling\n",
    "2. **Calculate portfolio statistics** including returns, volatility, and correlations  \n",
    "3. **Implement Monte Carlo simulation** for portfolio exploration\n",
    "4. **Find optimal portfolios** using both simulation and analytical methods\n",
    "5. **Calculate risk metrics** (VaR/CVaR) using multiple approaches\n",
    "6. **Create comprehensive visualizations** for analysis and presentation\n",
    "7. **Apply practical constraints** for real-world portfolio management\n",
    "\n",
    "**Advanced Extensions Completed:**\n",
    "- âœ… Risk-free asset integration and Capital Allocation Line\n",
    "- âœ… Constrained optimization with realistic bounds\n",
    "- âœ… Multiple objective function comparison\n",
    "- âœ… Comprehensive risk measurement methods\n",
    "- âœ… Advanced visualization dashboard\n",
    "\n",
    "**Next Steps for Students:**\n",
    "- Implement dynamic rebalancing strategies\n",
    "- Add transaction costs and market impact\n",
    "- Explore alternative risk measures (drawdown, semi-variance)\n",
    "- Study factor models and risk attribution\n",
    "- Learn about Black-Litterman model improvements\n",
    "\n",
    "---\n",
    "\n",
    "**ðŸŽ“ Instructor Final Notes:**\n",
    "- Emphasize MPT assumptions and limitations in practice\n",
    "- Discuss estimation risk and parameter uncertainty\n",
    "- Connect to broader portfolio management concepts\n",
    "- Encourage critical thinking about model limitations\n",
    "- Prepare students for advanced portfolio theory topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb19a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final execution summary and teaching assessment\n",
    "import time\n",
    "print(\"âœ… INSTRUCTOR NOTEBOOK COMPLETED\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"ðŸ“Š Comprehensive Analysis Summary:\")\n",
    "print(f\"  - Complete portfolio optimization implementation\")\n",
    "print(f\"  - Multiple VaR/CVaR calculation methods\")\n",
    "print(f\"  - Advanced constraint handling\")\n",
    "print(f\"  - Comprehensive visualization dashboard\")\n",
    "print(f\"  - All exercise solutions provided\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Student Learning Outcomes Achieved:\")\n",
    "print(f\"  âœ… Modern Portfolio Theory implementation\")\n",
    "print(f\"  âœ… Monte Carlo simulation techniques\")\n",
    "print(f\"  âœ… Risk measurement and management\")\n",
    "print(f\"  âœ… Optimization with practical constraints\")\n",
    "print(f\"  âœ… Professional-quality analysis and visualization\")\n",
    "\n",
    "print(f\"\\nðŸ“š Teaching Effectiveness:\")\n",
    "print(f\"  - Theory connected to practical implementation\")\n",
    "print(f\"  - Multiple solution approaches demonstrated\")\n",
    "print(f\"  - Real-world constraints and considerations\")\n",
    "print(f\"  - Comprehensive error handling and robustness\")\n",
    "\n",
    "print(f\"\\nâ±ï¸ Instructor notebook execution completed!\")\n",
    "print(f\"   Ready for classroom deployment and student guidance\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
